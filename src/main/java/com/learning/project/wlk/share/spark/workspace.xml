<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="ChangeListManager">
    <list default="true" id="9f0ea0db-2870-496a-a42f-3e1ed8122d22" name="Default Changelist" comment="" />
    <option name="EXCLUDED_CONVERTED_TO_IGNORED" value="true" />
    <option name="SHOW_DIALOG" value="false" />
    <option name="HIGHLIGHT_CONFLICTS" value="true" />
    <option name="HIGHLIGHT_NON_ACTIVE_CHANGELIST" value="false" />
    <option name="LAST_RESOLUTION" value="IGNORE" />
  </component>
  <component name="CodeStyleSettingsInfer">
    <option name="done" value="true" />
  </component>
  <component name="DatabaseView">
    <option name="SHOW_INTERMEDIATE" value="true" />
    <option name="GROUP_DATA_SOURCES" value="true" />
    <option name="GROUP_SCHEMA" value="true" />
    <option name="GROUP_CONTENTS" value="false" />
    <option name="SORT_POSITIONED" value="false" />
    <option name="SHOW_EMPTY_GROUPS" value="false" />
    <option name="AUTO_SCROLL_FROM_SOURCE" value="false" />
    <option name="HIDDEN_KINDS">
      <set />
    </option>
    <expand />
    <select />
  </component>
  <component name="FileTemplateManagerImpl">
    <option name="RECENT_TEMPLATES">
      <list>
        <option value="Scala Object" />
      </list>
    </option>
  </component>
  <component name="MavenImportPreferences">
    <option name="generalSettings">
      <MavenGeneralSettings>
        <option name="localRepository" value="E:\Env\apache-maven-3.6.0-bin\apache-maven-3.6.0\localRepository" />
        <option name="mavenHome" value="E:/Env/apache-maven-3.6.0-bin/apache-maven-3.6.0" />
      </MavenGeneralSettings>
    </option>
  </component>
  <component name="ProjectCodeStyleSettingsMigration">
    <option name="version" value="1" />
  </component>
  <component name="ProjectId" id="1QaHNAIh7ufBBDAIyn9Vrez8vCB" />
  <component name="PropertiesComponent">
    <property name="WebServerToolWindowFactoryState" value="false" />
    <property name="aspect.path.notification.shown" value="true" />
    <property name="last_directory_selection" value="$PROJECT_DIR$/src/main/java" />
    <property name="last_opened_file_path" value="$PROJECT_DIR$/../DCjingsai/marathonSample" />
    <property name="node.js.detected.package.eslint" value="true" />
    <property name="node.js.detected.package.tslint" value="true" />
    <property name="node.js.path.for.package.eslint" value="project" />
    <property name="node.js.path.for.package.tslint" value="project" />
    <property name="node.js.selected.package.eslint" value="(autodetect)" />
    <property name="node.js.selected.package.tslint" value="(autodetect)" />
    <property name="project.structure.last.edited" value="Modules" />
    <property name="project.structure.proportion" value="0.0" />
    <property name="project.structure.side.proportion" value="0.23433584" />
    <property name="settings.editor.selected.configurable" value="preferences.editor" />
  </component>
  <component name="RecentsManager">
    <key name="CopyFile.RECENT_KEYS">
      <recent name="D:\IdeaProjects\testSparkCore" />
    </key>
  </component>
  <component name="RunDashboard">
    <option name="ruleStates">
      <list>
        <RuleState>
          <option name="name" value="ConfigurationTypeDashboardGroupingRule" />
        </RuleState>
        <RuleState>
          <option name="name" value="StatusDashboardGroupingRule" />
        </RuleState>
      </list>
    </option>
  </component>
  <component name="RunManager" selected="Application.startMaster">
    <configuration name="startMaster" type="Application" factoryName="Application">
      <envs>
        <env name="SPARK_HOME" value="E:\Env\spark-2.3.2-bin-hadoop2.7" />
        <env name="SPARK_CONF_DIR" value="E:\Env\spark-2.3.2-bin-hadoop2.7\conf" />
        <env name="SPARK_NICENESS" value="0" />
        <env name="SPARK_LOG_DIR" value="E:\Env\spark-2.3.2-bin-hadoop2.7\log" />
        <env name="PWD" value="E:\Env\spark-2.3.2-bin-hadoop2.7\sbin" />
        <env name="SPARK_ENV_LOADED" value="1" />
        <env name="SPARK_PRINT_LAUNCH_COMMAND" value="1" />
        <env name="PYSPARK_PYTHONPATH_SET" value="1" />
        <env name="PYTHONPATH" value="E:\Env\spark-2.3.2-bin-hadoop2.7\python\lib\py4j-0.10.7-src.zip:E:\Env\spark-2.3.2-bin-hadoop2.7\python:" />
        <env name="SPARK_IDENT_STRING" value="WLK" />
        <env name="SPARK_SCALA_VERSION" value="2.11" />
        <env name="SPARK_JARS_DIR" value="${SPARK_HOME}/jars" />
        <env name="LAUNCH_CLASSPATH" value="E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\activation-1.1.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\aircompressor-0.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\antlr-2.7.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\antlr-runtime-3.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\antlr4-runtime-4.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\aopalliance-1.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\aopalliance-repackaged-2.4.0-b34.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\apache-log4j-extras-1.2.17.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\apacheds-i18n-2.0.0-M15.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\apacheds-kerberos-codec-2.0.0-M15.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\api-asn1-api-1.0.0-M20.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\api-util-1.0.0-M20.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\arpack_combined_all-0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\arrow-format-0.8.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\arrow-memory-0.8.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\arrow-vector-0.8.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\automaton-1.11-8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\avro-1.7.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\avro-ipc-1.7.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\avro-mapred-1.7.7-hadoop2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\base64-2.3.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\bcprov-jdk15on-1.58.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\bonecp-0.8.0.RELEASE.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\breeze-macros_2.11-0.13.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\breeze_2.11-0.13.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\calcite-avatica-1.2.0-incubating.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\calcite-core-1.2.0-incubating.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\calcite-linq4j-1.2.0-incubating.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\chill-java-0.8.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\chill_2.11-0.8.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-beanutils-1.7.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-beanutils-core-1.8.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-cli-1.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-codec-1.10.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-collections-3.2.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-compiler-3.0.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-compress-1.4.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-configuration-1.6.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-crypto-1.0.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-dbcp-1.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-digester-1.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-httpclient-3.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-io-2.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-lang-2.6.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-lang3-3.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-logging-1.1.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-math3-3.4.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-net-2.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-pool-1.5.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\compress-lzf-1.0.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\core-1.1.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\curator-client-2.7.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\curator-framework-2.7.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\curator-recipes-2.7.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\datanucleus-api-jdo-3.2.6.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\datanucleus-core-3.2.10.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\datanucleus-rdbms-3.2.9.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\derby-10.12.1.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\eigenbase-properties-1.1.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\flatbuffers-1.2.0-3f79e055.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\generex-1.0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\gson-2.2.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\guava-14.0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\guice-3.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\guice-servlet-3.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-annotations-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-auth-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-client-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-common-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-hdfs-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-mapreduce-client-app-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-mapreduce-client-common-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-mapreduce-client-core-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-mapreduce-client-jobclient-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-mapreduce-client-shuffle-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-yarn-api-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-yarn-client-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-yarn-common-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-yarn-server-common-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-yarn-server-web-proxy-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hive-beeline-1.2.1.spark2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hive-cli-1.2.1.spark2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hive-exec-1.2.1.spark2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hive-jdbc-1.2.1.spark2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hive-metastore-1.2.1.spark2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hk2-api-2.4.0-b34.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hk2-locator-2.4.0-b34.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hk2-utils-2.4.0-b34.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hppc-0.7.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\htrace-core-3.1.0-incubating.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\httpclient-4.5.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\httpcore-4.4.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\ivy-2.4.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-annotations-2.6.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-core-2.6.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-core-asl-1.9.13.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-databind-2.6.7.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-dataformat-yaml-2.6.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-jaxrs-1.9.13.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-mapper-asl-1.9.13.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-module-jaxb-annotations-2.6.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-module-paranamer-2.7.9.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-module-scala_2.11-2.6.7.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-xc-1.9.13.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\janino-3.0.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\java-xmlbuilder-1.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\JavaEWAH-0.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javassist-3.18.1-GA.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javax.annotation-api-1.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javax.inject-1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javax.inject-2.4.0-b34.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javax.servlet-api-3.1.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javax.ws.rs-api-2.0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javolution-5.5.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jaxb-api-2.2.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jcl-over-slf4j-1.7.16.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jdo-api-3.0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-client-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-common-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-container-servlet-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-container-servlet-core-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-guava-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-media-jaxb-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-server-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jets3t-0.9.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jetty-6.1.26.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jetty-util-6.1.26.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jline-2.12.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\joda-time-2.9.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jodd-core-3.5.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jpam-1.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\json4s-ast_2.11-3.2.11.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\json4s-core_2.11-3.2.11.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\json4s-jackson_2.11-3.2.11.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jsp-api-2.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jsr305-1.3.9.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jta-1.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jtransforms-2.4.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jul-to-slf4j-1.7.16.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\kryo-shaded-3.0.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\kubernetes-client-3.0.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\kubernetes-model-2.0.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\leveldbjni-all-1.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\libfb303-0.9.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\libthrift-0.9.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\log4j-1.2.17.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\logging-interceptor-3.8.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\lz4-java-1.4.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\machinist_2.11-0.6.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\macro-compat_2.11-1.1.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\mesos-1.4.0-shaded-protobuf.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\metrics-core-3.1.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\metrics-graphite-3.1.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\metrics-json-3.1.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\metrics-jvm-3.1.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\minlog-1.3.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\netty-3.9.9.Final.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\netty-all-4.1.17.Final.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\objenesis-2.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\okhttp-3.8.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\okio-1.13.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\opencsv-2.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\orc-core-1.4.4-nohive.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\orc-mapreduce-1.4.4-nohive.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\oro-2.0.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\osgi-resource-locator-1.0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\paranamer-2.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-column-1.8.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-common-1.8.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-encoding-1.8.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-format-2.3.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-hadoop-1.8.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-hadoop-bundle-1.6.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-jackson-1.8.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\protobuf-java-2.5.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\py4j-0.10.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\pyrolite-4.13.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\RoaringBitmap-0.5.11.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\scala-compiler-2.11.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\scala-library-2.11.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\scala-parser-combinators_2.11-1.0.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\scala-reflect-2.11.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\scala-xml_2.11-1.0.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\scalap-2.11.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\shapeless_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\slf4j-api-1.7.16.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\slf4j-log4j12-1.7.16.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\snakeyaml-1.15.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\snappy-0.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\snappy-java-1.1.2.6.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-catalyst_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-core_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-graphx_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-hive-thriftserver_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-hive_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-kubernetes_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-kvstore_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-launcher_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-mesos_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-mllib-local_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-mllib_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-network-common_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-network-shuffle_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-repl_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-sketch_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-sql_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-streaming_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-tags_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-unsafe_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-yarn_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spire-macros_2.11-0.13.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spire_2.11-0.13.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\ST4-4.0.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\stax-api-1.0-2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\stax-api-1.0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\stream-2.7.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\stringtemplate-3.2.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\super-csv-2.2.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\univocity-parsers-2.5.9.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\validation-api-1.1.0.Final.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\xbean-asm5-shaded-4.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\xercesImpl-2.9.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\xmlenc-0.52.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\xz-1.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\zjsonpatch-0.3.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\zookeeper-3.4.6.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\zstd-jni-1.3.2-2.jar" />
      </envs>
      <option name="MAIN_CLASS_NAME" value="org.apache.spark.deploy.master.Master" />
      <module name="testSparkCore" />
      <option name="PROGRAM_PARAMETERS" value="--host localhost --port 7077 --webui-port 8080" />
      <shortenClasspath name="NONE" />
      <option name="VM_PARAMETERS" value="-Xmx128m -cp .;E:\\Env\\spark-2.3.2-bin-hadoop2.7\\conf\;E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\*;D:\\IdeaProjects\\testSparkCore\\target\\testSparkCore-1.0-SNAPSHOT.jar" />
      <method v="2">
        <option name="Make" enabled="true" />
      </method>
    </configuration>
    <configuration name="startWorker" type="Application" factoryName="Application">
      <envs>
        <env name="SPARK_HOME" value="E:\Env\spark-2.3.2-bin-hadoop2.7" />
        <env name="SPARK_CONF_DIR" value="E:\Env\spark-2.3.2-bin-hadoop2.7\conf" />
        <env name="SPARK_NICENESS" value="0" />
        <env name="SPARK_LOG_DIR" value="E:\Env\spark-2.3.2-bin-hadoop2.7\log" />
        <env name="PWD" value="E:\Env\spark-2.3.2-bin-hadoop2.7\sbin" />
        <env name="SPARK_ENV_LOADED" value="1" />
        <env name="SPARK_PRINT_LAUNCH_COMMAND" value="1" />
        <env name="PYSPARK_PYTHONPATH_SET" value="1" />
        <env name="PYTHONPATH" value="E:\Env\spark-2.3.2-bin-hadoop2.7\python\lib\py4j-0.10.7-src.zip:E:\Env\spark-2.3.2-bin-hadoop2.7\python:" />
        <env name="SPARK_IDENT_STRING" value="WLK" />
        <env name="SPARK_SCALA_VERSION" value="2.11" />
        <env name="SPARK_JARS_DIR" value="${SPARK_HOME}/jars" />
        <env name="LAUNCH_CLASSPATH" value="E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\activation-1.1.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\aircompressor-0.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\antlr-2.7.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\antlr-runtime-3.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\antlr4-runtime-4.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\aopalliance-1.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\aopalliance-repackaged-2.4.0-b34.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\apache-log4j-extras-1.2.17.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\apacheds-i18n-2.0.0-M15.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\apacheds-kerberos-codec-2.0.0-M15.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\api-asn1-api-1.0.0-M20.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\api-util-1.0.0-M20.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\arpack_combined_all-0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\arrow-format-0.8.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\arrow-memory-0.8.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\arrow-vector-0.8.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\automaton-1.11-8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\avro-1.7.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\avro-ipc-1.7.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\avro-mapred-1.7.7-hadoop2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\base64-2.3.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\bcprov-jdk15on-1.58.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\bonecp-0.8.0.RELEASE.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\breeze-macros_2.11-0.13.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\breeze_2.11-0.13.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\calcite-avatica-1.2.0-incubating.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\calcite-core-1.2.0-incubating.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\calcite-linq4j-1.2.0-incubating.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\chill-java-0.8.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\chill_2.11-0.8.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-beanutils-1.7.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-beanutils-core-1.8.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-cli-1.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-codec-1.10.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-collections-3.2.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-compiler-3.0.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-compress-1.4.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-configuration-1.6.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-crypto-1.0.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-dbcp-1.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-digester-1.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-httpclient-3.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-io-2.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-lang-2.6.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-lang3-3.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-logging-1.1.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-math3-3.4.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-net-2.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-pool-1.5.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\compress-lzf-1.0.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\core-1.1.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\curator-client-2.7.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\curator-framework-2.7.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\curator-recipes-2.7.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\datanucleus-api-jdo-3.2.6.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\datanucleus-core-3.2.10.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\datanucleus-rdbms-3.2.9.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\derby-10.12.1.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\eigenbase-properties-1.1.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\flatbuffers-1.2.0-3f79e055.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\generex-1.0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\gson-2.2.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\guava-14.0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\guice-3.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\guice-servlet-3.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-annotations-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-auth-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-client-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-common-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-hdfs-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-mapreduce-client-app-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-mapreduce-client-common-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-mapreduce-client-core-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-mapreduce-client-jobclient-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-mapreduce-client-shuffle-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-yarn-api-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-yarn-client-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-yarn-common-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-yarn-server-common-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-yarn-server-web-proxy-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hive-beeline-1.2.1.spark2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hive-cli-1.2.1.spark2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hive-exec-1.2.1.spark2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hive-jdbc-1.2.1.spark2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hive-metastore-1.2.1.spark2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hk2-api-2.4.0-b34.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hk2-locator-2.4.0-b34.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hk2-utils-2.4.0-b34.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hppc-0.7.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\htrace-core-3.1.0-incubating.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\httpclient-4.5.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\httpcore-4.4.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\ivy-2.4.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-annotations-2.6.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-core-2.6.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-core-asl-1.9.13.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-databind-2.6.7.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-dataformat-yaml-2.6.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-jaxrs-1.9.13.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-mapper-asl-1.9.13.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-module-jaxb-annotations-2.6.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-module-paranamer-2.7.9.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-module-scala_2.11-2.6.7.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-xc-1.9.13.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\janino-3.0.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\java-xmlbuilder-1.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\JavaEWAH-0.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javassist-3.18.1-GA.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javax.annotation-api-1.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javax.inject-1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javax.inject-2.4.0-b34.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javax.servlet-api-3.1.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javax.ws.rs-api-2.0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javolution-5.5.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jaxb-api-2.2.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jcl-over-slf4j-1.7.16.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jdo-api-3.0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-client-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-common-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-container-servlet-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-container-servlet-core-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-guava-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-media-jaxb-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-server-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jets3t-0.9.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jetty-6.1.26.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jetty-util-6.1.26.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jline-2.12.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\joda-time-2.9.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jodd-core-3.5.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jpam-1.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\json4s-ast_2.11-3.2.11.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\json4s-core_2.11-3.2.11.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\json4s-jackson_2.11-3.2.11.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jsp-api-2.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jsr305-1.3.9.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jta-1.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jtransforms-2.4.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jul-to-slf4j-1.7.16.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\kryo-shaded-3.0.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\kubernetes-client-3.0.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\kubernetes-model-2.0.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\leveldbjni-all-1.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\libfb303-0.9.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\libthrift-0.9.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\log4j-1.2.17.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\logging-interceptor-3.8.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\lz4-java-1.4.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\machinist_2.11-0.6.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\macro-compat_2.11-1.1.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\mesos-1.4.0-shaded-protobuf.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\metrics-core-3.1.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\metrics-graphite-3.1.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\metrics-json-3.1.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\metrics-jvm-3.1.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\minlog-1.3.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\netty-3.9.9.Final.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\netty-all-4.1.17.Final.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\objenesis-2.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\okhttp-3.8.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\okio-1.13.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\opencsv-2.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\orc-core-1.4.4-nohive.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\orc-mapreduce-1.4.4-nohive.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\oro-2.0.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\osgi-resource-locator-1.0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\paranamer-2.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-column-1.8.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-common-1.8.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-encoding-1.8.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-format-2.3.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-hadoop-1.8.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-hadoop-bundle-1.6.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-jackson-1.8.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\protobuf-java-2.5.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\py4j-0.10.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\pyrolite-4.13.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\RoaringBitmap-0.5.11.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\scala-compiler-2.11.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\scala-library-2.11.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\scala-parser-combinators_2.11-1.0.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\scala-reflect-2.11.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\scala-xml_2.11-1.0.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\scalap-2.11.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\shapeless_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\slf4j-api-1.7.16.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\slf4j-log4j12-1.7.16.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\snakeyaml-1.15.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\snappy-0.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\snappy-java-1.1.2.6.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-catalyst_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-core_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-graphx_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-hive-thriftserver_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-hive_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-kubernetes_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-kvstore_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-launcher_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-mesos_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-mllib-local_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-mllib_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-network-common_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-network-shuffle_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-repl_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-sketch_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-sql_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-streaming_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-tags_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-unsafe_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-yarn_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spire-macros_2.11-0.13.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spire_2.11-0.13.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\ST4-4.0.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\stax-api-1.0-2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\stax-api-1.0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\stream-2.7.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\stringtemplate-3.2.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\super-csv-2.2.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\univocity-parsers-2.5.9.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\validation-api-1.1.0.Final.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\xbean-asm5-shaded-4.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\xercesImpl-2.9.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\xmlenc-0.52.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\xz-1.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\zjsonpatch-0.3.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\zookeeper-3.4.6.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\zstd-jni-1.3.2-2.jar" />
      </envs>
      <option name="MAIN_CLASS_NAME" value="org.apache.spark.deploy.worker.Worker" />
      <module name="testSparkCore" />
      <option name="PROGRAM_PARAMETERS" value="--webui-port 8081 spark://localhost:7077" />
      <shortenClasspath name="NONE" />
      <option name="VM_PARAMETERS" value="-Xmx128m -cp .;E:\\Env\\spark-2.3.2-bin-hadoop2.7\\conf\;E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\*;D:\\IdeaProjects\\testSparkCore\\target\\testSparkCore-1.0-SNAPSHOT.jar" />
      <method v="2">
        <option name="Make" enabled="true" />
      </method>
    </configuration>
    <configuration name="testSpark" type="Application" factoryName="Application" temporary="true">
      <envs>
        <env name="SPARK_HOME" value="E:\Env\spark-2.3.2-bin-hadoop2.7" />
        <env name="SPARK_CONF_DIR" value="E:\Env\spark-2.3.2-bin-hadoop2.7\conf" />
        <env name="SPARK_NICENESS" value="0" />
        <env name="SPARK_LOG_DIR" value="E:\Env\spark-2.3.2-bin-hadoop2.7\log" />
        <env name="PWD" value="E:\Env\spark-2.3.2-bin-hadoop2.7\sbin" />
        <env name="SPARK_ENV_LOADED" value="1" />
        <env name="SPARK_PRINT_LAUNCH_COMMAND" value="1" />
        <env name="PYSPARK_PYTHONPATH_SET" value="1" />
        <env name="PYTHONPATH" value="E:\Env\spark-2.3.2-bin-hadoop2.7\python\lib\py4j-0.10.7-src.zip:E:\Env\spark-2.3.2-bin-hadoop2.7\python:" />
        <env name="SPARK_IDENT_STRING" value="WLK" />
        <env name="SPARK_SCALA_VERSION" value="2.11" />
        <env name="SPARK_JARS_DIR" value="${SPARK_HOME}/jars" />
        <env name="LAUNCH_CLASSPATH" value="E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\activation-1.1.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\aircompressor-0.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\antlr-2.7.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\antlr-runtime-3.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\antlr4-runtime-4.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\aopalliance-1.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\aopalliance-repackaged-2.4.0-b34.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\apache-log4j-extras-1.2.17.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\apacheds-i18n-2.0.0-M15.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\apacheds-kerberos-codec-2.0.0-M15.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\api-asn1-api-1.0.0-M20.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\api-util-1.0.0-M20.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\arpack_combined_all-0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\arrow-format-0.8.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\arrow-memory-0.8.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\arrow-vector-0.8.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\automaton-1.11-8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\avro-1.7.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\avro-ipc-1.7.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\avro-mapred-1.7.7-hadoop2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\base64-2.3.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\bcprov-jdk15on-1.58.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\bonecp-0.8.0.RELEASE.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\breeze-macros_2.11-0.13.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\breeze_2.11-0.13.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\calcite-avatica-1.2.0-incubating.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\calcite-core-1.2.0-incubating.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\calcite-linq4j-1.2.0-incubating.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\chill-java-0.8.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\chill_2.11-0.8.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-beanutils-1.7.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-beanutils-core-1.8.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-cli-1.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-codec-1.10.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-collections-3.2.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-compiler-3.0.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-compress-1.4.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-configuration-1.6.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-crypto-1.0.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-dbcp-1.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-digester-1.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-httpclient-3.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-io-2.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-lang-2.6.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-lang3-3.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-logging-1.1.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-math3-3.4.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-net-2.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\commons-pool-1.5.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\compress-lzf-1.0.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\core-1.1.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\curator-client-2.7.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\curator-framework-2.7.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\curator-recipes-2.7.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\datanucleus-api-jdo-3.2.6.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\datanucleus-core-3.2.10.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\datanucleus-rdbms-3.2.9.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\derby-10.12.1.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\eigenbase-properties-1.1.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\flatbuffers-1.2.0-3f79e055.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\generex-1.0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\gson-2.2.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\guava-14.0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\guice-3.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\guice-servlet-3.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-annotations-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-auth-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-client-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-common-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-hdfs-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-mapreduce-client-app-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-mapreduce-client-common-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-mapreduce-client-core-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-mapreduce-client-jobclient-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-mapreduce-client-shuffle-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-yarn-api-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-yarn-client-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-yarn-common-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-yarn-server-common-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hadoop-yarn-server-web-proxy-2.7.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hive-beeline-1.2.1.spark2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hive-cli-1.2.1.spark2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hive-exec-1.2.1.spark2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hive-jdbc-1.2.1.spark2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hive-metastore-1.2.1.spark2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hk2-api-2.4.0-b34.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hk2-locator-2.4.0-b34.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hk2-utils-2.4.0-b34.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\hppc-0.7.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\htrace-core-3.1.0-incubating.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\httpclient-4.5.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\httpcore-4.4.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\ivy-2.4.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-annotations-2.6.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-core-2.6.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-core-asl-1.9.13.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-databind-2.6.7.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-dataformat-yaml-2.6.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-jaxrs-1.9.13.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-mapper-asl-1.9.13.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-module-jaxb-annotations-2.6.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-module-paranamer-2.7.9.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-module-scala_2.11-2.6.7.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jackson-xc-1.9.13.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\janino-3.0.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\java-xmlbuilder-1.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\JavaEWAH-0.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javassist-3.18.1-GA.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javax.annotation-api-1.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javax.inject-1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javax.inject-2.4.0-b34.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javax.servlet-api-3.1.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javax.ws.rs-api-2.0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\javolution-5.5.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jaxb-api-2.2.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jcl-over-slf4j-1.7.16.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jdo-api-3.0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-client-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-common-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-container-servlet-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-container-servlet-core-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-guava-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-media-jaxb-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jersey-server-2.22.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jets3t-0.9.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jetty-6.1.26.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jetty-util-6.1.26.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jline-2.12.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\joda-time-2.9.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jodd-core-3.5.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jpam-1.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\json4s-ast_2.11-3.2.11.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\json4s-core_2.11-3.2.11.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\json4s-jackson_2.11-3.2.11.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jsp-api-2.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jsr305-1.3.9.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jta-1.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jtransforms-2.4.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\jul-to-slf4j-1.7.16.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\kryo-shaded-3.0.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\kubernetes-client-3.0.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\kubernetes-model-2.0.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\leveldbjni-all-1.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\libfb303-0.9.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\libthrift-0.9.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\log4j-1.2.17.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\logging-interceptor-3.8.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\lz4-java-1.4.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\machinist_2.11-0.6.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\macro-compat_2.11-1.1.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\mesos-1.4.0-shaded-protobuf.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\metrics-core-3.1.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\metrics-graphite-3.1.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\metrics-json-3.1.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\metrics-jvm-3.1.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\minlog-1.3.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\netty-3.9.9.Final.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\netty-all-4.1.17.Final.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\objenesis-2.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\okhttp-3.8.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\okio-1.13.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\opencsv-2.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\orc-core-1.4.4-nohive.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\orc-mapreduce-1.4.4-nohive.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\oro-2.0.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\osgi-resource-locator-1.0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\paranamer-2.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-column-1.8.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-common-1.8.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-encoding-1.8.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-format-2.3.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-hadoop-1.8.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-hadoop-bundle-1.6.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\parquet-jackson-1.8.3.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\protobuf-java-2.5.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\py4j-0.10.7.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\pyrolite-4.13.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\RoaringBitmap-0.5.11.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\scala-compiler-2.11.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\scala-library-2.11.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\scala-parser-combinators_2.11-1.0.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\scala-reflect-2.11.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\scala-xml_2.11-1.0.5.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\scalap-2.11.8.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\shapeless_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\slf4j-api-1.7.16.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\slf4j-log4j12-1.7.16.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\snakeyaml-1.15.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\snappy-0.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\snappy-java-1.1.2.6.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-catalyst_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-core_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-graphx_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-hive-thriftserver_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-hive_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-kubernetes_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-kvstore_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-launcher_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-mesos_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-mllib-local_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-mllib_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-network-common_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-network-shuffle_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-repl_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-sketch_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-sql_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-streaming_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-tags_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-unsafe_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spark-yarn_2.11-2.3.2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spire-macros_2.11-0.13.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\spire_2.11-0.13.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\ST4-4.0.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\stax-api-1.0-2.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\stax-api-1.0.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\stream-2.7.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\stringtemplate-3.2.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\super-csv-2.2.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\univocity-parsers-2.5.9.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\validation-api-1.1.0.Final.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\xbean-asm5-shaded-4.4.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\xercesImpl-2.9.1.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\xmlenc-0.52.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\xz-1.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\zjsonpatch-0.3.0.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\zookeeper-3.4.6.jar E:\\Env\\spark-2.3.2-bin-hadoop2.7\\jars\\zstd-jni-1.3.2-2.jar" />
      </envs>
      <option name="MAIN_CLASS_NAME" value="org.apache.spark.deploy.SparkSubmit" />
      <module name="testSparkCore" />
      <option name="PROGRAM_PARAMETERS" value="--master spark://localhost:7077 --class cn.wlk.testSparkCore.testSpark D:\IdeaProjects\testSparkCore\target\testSparkCore-1.0-SNAPSHOT.jar" />
      <shortenClasspath name="NONE" />
      <method v="2">
        <option name="Make" enabled="true" />
      </method>
    </configuration>
    <list>
      <item itemvalue="Application.startMaster" />
      <item itemvalue="Application.startWorker" />
      <item itemvalue="Application.testSpark" />
    </list>
    <recent_temporary>
      <list>
        <item itemvalue="Application.testSpark" />
      </list>
    </recent_temporary>
  </component>
  <component name="ScalaProjectSettings">
    <option name="ignorePerformance" value="true" />
  </component>
  <component name="StructureViewFactory">
    <option name="AUTOSCROLL_MODE" value="false" />
  </component>
  <component name="SvnConfiguration">
    <configuration />
  </component>
  <component name="TaskManager">
    <task active="true" id="Default" summary="Default task">
      <changelist id="9f0ea0db-2870-496a-a42f-3e1ed8122d22" name="Default Changelist" comment="" />
      <created>1568001745020</created>
      <option name="number" value="Default" />
      <option name="presentableId" value="Default" />
      <updated>1568001745020</updated>
      <workItem from="1568001746952" duration="49000" />
      <workItem from="1568001800901" duration="305000" />
      <workItem from="1568002141756" duration="18702000" />
      <workItem from="1569511483902" duration="43000" />
      <workItem from="1573914627031" duration="1441000" />
    </task>
    <servers />
  </component>
  <component name="TypeScriptGeneratedFilesManager">
    <option name="version" value="1" />
  </component>
</project>