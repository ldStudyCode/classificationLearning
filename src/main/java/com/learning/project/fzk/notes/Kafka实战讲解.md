[TOC]

> 参考资料：
>
> 1. 《Kafka权威指南》
> 2. kafka官网

# 1. Kafka是什么

是一个高吞吐量、高可用的分布式消息系统。

## 1.1 Kafka的优势

* 支持多个生产者：适合从多个数据源来收集数据，并以统一的数据格式对外提供数据；
* 支持多个消费者：多消费者从一个topic中读取时，互不影响；
* 基于磁盘的数据存储：允许消费者非实时地读取消息，达到削峰平谷的目的；
* 伸缩性强：可以从单个broker在线扩展到上百个broker的集群，在线扩容不影响系统可用性；
* 代码解耦：消息的发送者不会直接把消息发送给接受者，以此来达到生产者和消费者之间的解耦的目的。

## 1.2 使用场景

* 活动跟踪：即埋点系统的后台系统，用于跟踪用户活动记录；
* 传递消息：比如短信、邮件；
* 提交日志：对记录日志进行削峰填谷，且当日志服务不可用时，可以短暂的保存近期日志；
* 流处理：类似于实时数据的mapReduce；



# 2. Kafka原理

## 2.1 概念解释

broker：消息处理的节点，通常一台服务器上部署一个broker；

controller：就是第一个注册进zookeeper的broker，除了具有一般broker功能外，还负责leader的选举；

topic：逻辑单位，用于区分业务。比如信息流的曝光和点击，可以使用两个topic来表示；

partition：一个topic划分为多个partition，每个partition是一个有序的队列；

segment：partition物理上由多个segment组成；

offset：partition中每一条消息的唯一标识；

producer：向broker发送消息的客户端；

consumer：从broker读取消息的客户端；

consumer group： 消费者组，多个组可以同时独立地消费一条消息；

消息结构：每条消息使用一个三元组表示：`<topic, key, message>` 

## 2.2 数据流向

当producer发来一条消息时，Kafka是如何接收、存储这条消息，又是如何让这条消息被consumer消费，最终如何删除的。Kafka集群在对业务有感知的层面，数据流向如下：

![img](https://upload-images.jianshu.io/upload_images/908013-c6748208af53d9d3.png)

* leader和follower：leader负责所有读写请求，follower被动地复制leader数据。如果leader宕机，则follower之一将自动成为新领导者。 每个服务器充当其某些分区的领导者，而充当其他分区的跟随者，因此群集中的负载得到了很好的平衡。
* 消息放到哪个partition中？生产者将消息按照指定规则放入某一个partition，可采用轮询、哈希、自定义规则等多种方式。
* 消息删除：可以设置过期时间，消息过期后自动被kafka删除。
* 由于一个主题内包含多个分区，因此无法在整个主题范围内保证消息的顺序，但可以保证消息在单个分区内的顺序。



## 2.3 高可用

本节介绍，Kafka如何利用分布式部署的优势，来保障服务高可用的，即使在部分broker宕机时仍能保证高可用性。

### 2.3.1 partition分配

Kafka通过一系列的partition分配策略，来保证即使有一些机器宕机，这些机器上的数据仍然存在于其他机器上。基本原则是：

* 在broker之间平均分配partition；
* 确保一个分区的每个副本分布在不同broker上，即禁止连个副本在同一台机器上，这样的复制没有用；
* 若broker指定了机架信息，尽可能把一个分区的每个副本分配到不同机架的broker上，这是为了保证一个机架的不可用导致整体分区不可用。

那么根据这些原则，假设有N台机器，i个待分配的leader分区，每个leader有j个follower，则：

* 第 $i$ 个Partition分配到第 $(i \mod n)$ 个Broker上；
* 第 $i$ 个Partition的第 $j$ 个副本分配到第 $((i + j) \mod n)$ 个Broker上。

总之，错开均匀放置。leader副本和follower副本之间，通过ISR列表机制保持同步。

### 2.3.2 ISR列表机制

冗余备份的方案一般有以下两种：

* 同步备份：消息可靠，但等待时间过长；

* 异步备份。无法保证可靠性。


ISR列表机制是二者的结合，避开了二者的缺点。ISR列表是一个同步副本列表，由leader副本保存。这个列表中保存了所有与leader保持同步了的副本列表。

那么kafka是如何定义一个follower是否与leader保持同步的呢？需要满足以下条件：

* 与zookeeper之间保持6秒一次的心跳；
* 过去10秒内从leader那里获取过最新消息；

kafka认为，如果一个follower在10s内没有请求任何消息，或者虽然请求消息，但在10s内没有请求最新的数据，或者没有跟zookeeper保持过心跳，那么这个follower就是不同步的。不同步的后果是，在leader失效时，它没有资格竞选新的leader——毕竟它没有包含全部的消息。

这个时间间隔可以通过 `replica.lag.time.max.ms` 参数配置，默认10s。

复制到所有ISR列表的副本后，消息才被看作可靠的。所有消费者只能看到已经复制到ISR的消息。如图：

![img](https://i.loli.net/2019/11/23/WGyqEHvBftjpdw7.jpg)

### 2.3.3 rebalance机制

rebalance本质上是一种协议，规定了一个consumer group下的所有consumer如何达成一致来分配订阅topic的每个分区。


### 2.3.4 高可用配置

前面介绍了kafka保证高可用的一些机制，本节讲解如何通过配置让项目中的kafka真正变得高可用——毕竟不同项目的目的不同，有些业务更看重吞吐量，允许少量丢失数据，有些项目一条数据都不允许丢失。



**对broker和topic的配置**

* **复制系数**：broker级别配置 `default.repication.factor` ，topic级别配置 `replication.factor` 。一般配置为3即可保证高可用，银行系统中可配置为5。若支持跨机架部署，可配置每个broker的机架号 `broker.rack` ，kafka在分配partition时会尽量跨机架分配；
* **不完全leader选举**：当leader不可用时，zookeeper会自动从ISR列表中选举出一个可用的新leader。但如果此时ISR列表为空，是否允许从一个不在ISR列表中的follower中选出一个leader呢？通过设置 `unclean.leader.election` 可以配置这个选项：
  * 若配置为true，表明允许从非ISR列表中选举leader，会丢失部分数据。常用于用户行为收集系统；
  * 若配置为false，表明宁可服务不可用，也不要毛线处理错误消息。常用于银行系统；
* **最少同步副本**：尽管有了ISR列表机制，但ISR列表是随时变化的。很有可能ISR列表中只剩下leader了，那么当它也不可用时，数据就会丢失了。因此，kafka提供了最少同步副本的配置，即ISR列表的最小长度。假如最少同步副本数为2，那么kafka会保证至少存活1个follower的时候才能接收数据。



**对生产者的配置**

* **发送确认**：指定必须有多少个副本接收到消息，生产者才认为是写入成功的，参数名称是 `acks` ，可配置为：

  * acks=0：生产者根本不管kafka有没有成功接收，有可能丢失消息，但吞吐量很高；
  * acks=1（默认）：只要leader接收完成，生产者就认为是完成了。仍然有可能会丢失消息；
  * acks=all：当ISR列表中的所有副本都收到消息时，生产者才会收到成功响应。最安全，但延迟更高；

* **重试次数**：对于可重试的错误（如leader由于正在选举中而不可用，或网络问题），这类问题一般都是几秒钟后可自动恢复的，因此kafka提供了自动重试机制。参数名称是 `retries` 。

  但要注意的是，kafka的重试机制只能保证“至少被保存一次（at-least-once）”和“至多被保存一次（at-most-once）”，无法保证“只被保存一次（exactly-once）”。由于网络延迟导致的重试，很可能让消息重复发送，可以在消息加唯一标识，或在消费者逻辑中做幂等处理，来解决重复消费问题。

  注：kafka0.11以上版本中，通过其他方式支持了exactly-once语义。



**对消费者的配置**

前提：由于消费者会有宕机重启的情况，重启后必须知道之前被读到的偏移量是多少，因此消费者需要向broker上“提交”偏移量。如果消费者提交了偏移量却未能处理完消息，那就有可能造成消息丢失，这也是消费者丢失消息的主要原因。因此，对于不同可靠性需求的系统，偏移量提交的时间点和提交方式需要谨慎设置。

* 从最早/最晚读取：在没有偏移量可提交时，消费者会从partition的最早的一条开始读，还是从最近的一条开始读？可将 `auto.offset.reset` 配置成earliest或latest来设置。若是earlist，会导致读取大量重复数据，但可以保证最少的数据丢失。相反，若是latest，可以减少数据丢失，但会错过消息；
* 是否允许自动提交偏移量：设置参数 `enable.auto.commit = true` ，kafka会自动提交偏移量，否则需要在代码中手动提交偏移量。自动提交是默认5秒钟提交一次，使用 `auto.commit.interval.ms` 来设置。



## 2.4 高性能

如何在保证程序正确、高可用的基础上，实现中间件的高性能？下面内容是kafka保证高性能的优化点。

### 2.4.1 segment文件索引机制

partition底层不是使用一个大文件来存储，而是拆分成多个segment小文件，按指定的大小来切分。一个segment由日志文件和索引文件组成，两个文件一一对应。每个索引文件都是一个稀疏索引结构，使用二分查找法，就能很快地根据offset定位到指定的索引文件，并找到指定的索引。如图：

![img](https://i.loli.net/2019/11/23/SkHPO8IDQYhdZfw.jpg)



### 2.4.2 零拷贝

Kafka使用零拷贝技术向客户端发送消息。也就是说，Kafka直接把消息从文件发送到网络通道，而不需要经过任何中间缓冲区。

这是kafka和其他大部分数据库系统不一样的地方，其他数据库在发送数据时都会先保存在本地缓存里。这项技术避免了字节复制，也不需要管理内存缓冲区，从而获得更好的性能。



# 3. 测试与调优

## 3.1 测试

### 3.1.1 可用性测试

> 《Kafka权威指南》6.6节

kafka代码库提供了很多工具用于测试，可以用这些测试用例来测试我们的配置是否符合项目需求。同时也可以在写好业务逻辑后，部署在测试环境进行测试。通常会进行如下几项测试内容：

* 选举leader：停掉leader后，能否正常选举？会给生产者和消费者造成多久的不可用时间？重试次数能否真的重试成功？
* 选举controller：停掉controller（第一个启动的broker，负责选举leader）后，需要多久恢复？
* 依次重启broker：依次重启各台机器后，能否保证不丢失数据？
* 不完全leader选举：若停掉所有副本（确保每个副本都不在ISR列表中），然后启动一个不同步的broker会发生什么？
* 依次重启生产者和消费者：重启后能否保证不漏消费、不重复消费？



### 3.1.2 性能测试

可以使用kafka bin目录下自带的性能测试脚本kafka-producer-perf-test.sh，测试生产者性能。消费者同样也有脚本。

可指定消息总量、每条消息的字节数、每秒发送消息数等，脚本会按照配置向broker发送消息，并统计系统延迟时间。



## 3.2 调优

本节讲解在部署kafka时，如何根据项目需求和规模，选择最合适的硬件环境和配置参数。

### 3.2.1 zookeeper部署

在部署kafka之前，应首先部署zookeeper集群。zookeeper集群中应包含奇数个节点，因为zookeeper的选举策略是，需要半数以上的节点同意才能当选leader，如果是偶数节点可能导致票数相同的情况。因此，若部署了包含3个节点的zookeeper集群，那么它允许1个节点的失效。

### 3.2.2 kafka配置

常规配置：

* **broker.id**：broker的唯一标识符，默认是0，也可以被设置为任意整数；
* **port**：监听的端口号，默认是9092端口；
* **zookeper.connect**：用来连接zookeeper，其中存储了broker的元数据；
* **log.dirs**：消息文件存放路径，kafka中接收的消息也叫日志；
* **num.recovery.threads.per.data.dir**：broker启动或崩溃后恢复时，需要从其他broker上复制数据，而默认是单线程复制（即此参数为1）。可以改为多线程来加快恢复速度；
* **auto.create.topics.enable**：是否允许自动创建主题；

对topic的配置：

* **num.partitions**：配置分区数量，默认是1。如何选定分区数量？从以下几方面考虑：

  * 吞吐量：该topic需要达到多大的吞吐量（即每秒写入数据量）？一般一个分区都会有一个消费者，如果能估算出消费者的消费速度（如写库的速度限制，处理消息速度不超过每秒1000条），那么就能估算出大概每个分区的消费吞吐量；
  * 分区多的话，生产者和消费者可以多线程生产和处理消息，提高系统并发程度。但单个broker对分区个数有限制，因为分区越多，占用的内存越多，选举leader时间也越长；
  * 可以使用以下方式估算：分区数=目标吞吐量 / 单台消费者吞吐量。如，系统目标吞吐量是1GB/s，单台机器每秒可以消费50MB，那么可以设置分区数为20，相当于20个消费者进程并行处理，从而达到每秒钟1GB的吞吐量。

* **log.retention.ms**、**log.retention.bytes**：决定segment的删除策略，可以设置一个segment多少毫秒后删除，也可以设置一个topic占用多少空间后开始删除；

* **log.segement.bytes**：设置segment的大小，默认1GB。由于上面两个参数都是以segment为单位的，因此，如果segment设置过小，会导致频繁地关闭和分配新segment文件，降低磁盘写入效率；如果segment设置过大，会导致长时间填不满一个segment，本来早该过期的数据一直存放在segment中。

  以log.retention.ms为例，流程是：消息不断进入segment -> segment已满 -> segment被关闭 -> segment开始等待过期。即，一条消息进入时，如果所在segment一直未满，那么这条消息一直不会被删除。

* **message.max.bytes**：限制单条消息压缩后的大小，默认1MB。若超出，生产者会收到错误消息。

### 3.2.3 硬件选择

* **磁盘吞吐量**：影响生产速度。客户端发送消息后会一直等待，直到至少有一个服务器确认消息已经成功提交为止。因此，磁盘写入速度越快，生产的延迟就越低。固态硬盘的吞吐量要比机械硬盘更好；
* **磁盘容量**：影响数据容量。可以根据需求进行估算，如每天收到1TB消息，需要保留7天，那么就需要7TB的存储空间，当然还要预留额外空间来存储其他文件，以及应对流量增长；
* **内存**：影响消费速度。运行kafka的JVM不需要太大的内存，但会占用剩余的系统内存作为页缓存，来缓存正在使用中的segment。因此不建议把kafka和其他重要的应用程序部署在一起，因为它们需要共享页缓存，降低kafka消费性能；
* **网络**：影响吞吐量。网络吞吐量决定了了kafka处理数据量的上限，网络和磁盘存储是制约kafka规模的主要因素；
* **CPU**：没什么大影响。kafka对CPU的要求较低，需要用到CPU的地方寥寥无几：对客户端压缩传来的消息进行批量解压、设置偏移量、重新批量压缩、保存在磁盘上。

### 3.2.4 操作系统调优

操作系统参数一般配置在/etc/sysctl.conf文件中。

* **虚拟内存**：kafka的目的是尽可能高的吞吐量，因此需要避免内存交换（即内存页和磁盘页之间的交换），十分影响性能。可以设置 `vm.swappiness = 1` ，这表示当内存使用到1-1%=99%的时候，允许内存交换。这样设置的目的是，尽量减少内存页大量换进换出，提高系统性能。

  注，这个值默认是60%，即当内存占用40%的时候就开始内存交换了。

* **磁盘**：选择合适的文件系统；

* **网络**：可设置socket读写缓冲区的内存大小等。

### 3.2.5 JVM调优

G1垃圾回收器会自动根据工作负载情况进行自我调节，仅需要很少的配置就能完成工作。可设置：

* MaxGCPauseMillis：设置每次GC默认停顿时间，默认为200ms；
* InitiatingHeapOccupancyPercent：设置G1启动新一轮GC之前，可以使用的堆内存百分比，默认值是45%。也就是说，在堆内存使用率达到45%之前，G1不会启动垃圾回收。这个百分比包括新生代和老年代内存。

kafka对堆内存的使用率非常高，容易产生垃圾对象，因此可以将这两个值设置小一些，让垃圾回收器更频繁、但更快速地回收垃圾，勤拿少取，以提高系统吞吐量。如：

```
MaxGCPauseMillis = 20ms
InitiatingHeapOccupancyPercent = 35%
```



## 3.3 常见配置

本节讲解对于生产者和消费者的各种常见配置选项。

### 3.3.1 配置生产者

客户端向kafka发送消息的流程如下：

![img](https://i.loli.net/2019/11/22/DZ729gYyXje3T1C.jpg)

- 构造对象：客户端会首先创建一个对象，包含topic和要发送的内容value，也可以指定key和分区；
- 序列化：客户端将键和值对象序列化成字节数组；
- 分区器：决定这条消息要进入哪个partition。若对象中制定了，那么就直接用它；若没有指定，则根据键来决定；
- 发送至broker：先将消息添加进批次中，最后批量加入broker；
- 重试机制：若发送失败，则重试一定次数，若仍然失败，则返回错误消息。

在编写生产者代码中，可配置如下参数：

- bootstrap.servers：指定broker的地址列表；
- key.serializer：键的序列化器；
- value.serializer：值的序列化器；
- acks：指定必须有多少个副本接收到消息，生产者才认为是写入成功的：
  - acks=0：生产者根本不管kafka有没有成功接收，有可能丢失消息，但吞吐量很高；
  - acks=1（默认）：只要leader接收完成，生产者就认为是完成了。仍然有可能会丢失消息；
  - acks=all：当所有节点都收到消息时，生产者才会收到成功响应。最安全，但延迟更高；
- buffer.memory：生产者内存缓冲区的大小；
- compression.type：对消息的压缩算法，如snappy、gzip、lz4等，默认不会压缩；
- retries：重试次数。对于一些临时性的错误（如partition找不到leader），隔100ms后的重试是可能成功的；
- batch.size：一个批次可以使用的内存大小。批次即上图中发送给broker的内存中的缓存；
- linger.ms：发送批次前等待更多消息加入批次的时间，默认是0，即只要有可用线程，生产者就会发出消息；
- max.in.flight.request.per.connection：指定了生产者在收到服务器响应前可以发送多少个消息。若为1，可以保证写入顺序，即使发生了重试；
- timeout.ms、request.timeout.ms、metadata.fetch.timeout.ms：等待服务器响应的超时时间。

因此，若在对数据准确性和顺序性要求很高的场景下，可以设置重试次数（retries>0）以及max.in.flight.request.per.connection=1来保证顺序。

发送消息有三种方式：

- 发送并忘记：不关心是否正常到达，可能会丢失一些信息；
- 同步发送：客户端会获取到一个Future对象，调用get()方法阻塞就能知道是否成功；
- 异步发送：客户端指定一个回调函数，当发送成功后调用回调函数。

### 3.3.2 配置消费者

* fetch.min.bytes、fetch.max.wait.ms：指定消费者获取的最小字节数或等待的最长时间，这是为了在低谷时段降低消费者的负载；
* max.partition.fetch.bytes：指定了服务器从每个partition中返回给消费者的最大字节数；
* session.timeout.ms：指定了消费者在被认为死亡之前，可以与服务器断开连接的时间，默认3秒；
* auto.offset.reset：指定了消费者在读取一个没有偏移量的分区，或偏移量无效的情况下，该从最开始还是末尾继续读；
* enable.auto.commit：是否允许自动提交偏移量；
* partition.assignment.strategy：将partition分配给消费者机器的策略，可配置为range、roundRobin等。



# 附录

## 官方文档翻译

> 官网地址：http://kafka.apache.org/intro

流平台具有三个关键功能：

1. 发布和订阅记录流，类似于消息队列或企业消息传递系统。
2. 以容错的持久方式存储记录流。
3. 处理记录流。

Kafka通常用于两大类应用程序：

1. 建立实时流数据管道，以可靠地在系统或应用程序之间获取数据
2. 构建实时流应用程序以转换或响应数据流

要了解Kafka如何执行这些操作，让我们从头开始深入研究Kafka的功能。

首先几个概念：

Kafka在一个或多个可以跨越多个数据中心的服务器上作为集群运行。
Kafka集群将记录（records）流存储在称为topic的类别中。
每个记录由一个键，一个值和一个时间戳组成。

Kafka具有四个核心API：

1. Producer API允许应用程序将记录流发布到一个或多个Kafka主题。
2. Consumer API允许应用程序订阅一个或多个主题并处理为其生成的记录流。
3. Streams API允许应用程序充当流处理器，使用来自一个或多个主题的输入流，并生成一个或多个输出主题的输出流，从而有效地将输入流转换为输出流。
4. connector API允许构建和运行将Kafka主题连接到现有应用程序或数据系统的可重用生产者或使用者。例如，关系数据库的连接器可能会捕获对表的所有更改。

在Kafka中，客户端和服务器之间的通信是通过简单，高性能，与语言无关的TCP协议完成的。 该协议已版本化，并与旧版本保持向后兼容性。 我们为Kafka提供了Java客户端，但是客户端支持多种语言。

### 1 topic和log

首先，让我们深入探讨Kafka为记录流提供的核心抽象——topic。

主题是将记录发布到的类别或订阅源名称。 Kafka中的主题始终是多用户的； 也就是说，一个主题可以有零个，一个或多个消费者来订阅写入该主题的数据。

对于每个主题，Kafka集群都会维护一个分区日志，如下所示：

![img](http://kafka.apache.org/23/images/log_anatomy.png)

每个分区都是有序的，不变的记录序列，这些记录连续地附加到结构化的提交日志中。 每个分区中的记录都分配有一个称为offset的顺序ID号，该ID唯一地标识分区中的每个记录。

Kafka集群使用可配置的保留期限持久地保留所有已发布的记录（无论是否已使用它们）。 例如，如果将保留策略设置为两天，则在发布记录后的两天内，该记录可供使用，之后将被丢弃以释放空间。 Kafka不会因为数据量变大而性能降低，因此长时间存储数据不是问题。

![img](http://kafka.apache.org/23/images/log_consumer.png)

实际上，基于每个消费者保留的唯一元数据是该消费者在日志中的偏移量或位置。**此偏移量由消费者控制**：通常，消费者在读取记录时会线性地推进其偏移量，但是实际上，由于位置是由消费者控制的，因此它可以按喜欢的任何顺序消费记录。例如，消费者可以重置到较旧的偏移量以重新处理过去的数据，或者跳到最近的记录并从“现在”开始使用。

这些功能的组合意味着Kafka的消费者读取信息很方便——他们来来去去对集群或其他消费者没有太大影响。例如，您可以使用我们的命令行工具来任何topic的内容的最后几行，而无需更改任何现有使用者所消耗的内容。

**日志中的分区有多种用途**。首先，它们允许日志扩展到超出单个服务器所能容纳的大小。每个单独的分区都必须适合托管它的服务器，但是一个主题可能有很多分区，因此它可以处理任意数量的数据。其次，它们可充当并行单元。

### 2 服务器资源分布

partition分布在Kafka集群中的服务器上，每个服务器处理数据并要求共享partition。 每个partition都在多台（数量可配）服务器之间复制，以实现容错功能。

每个partition都有一个充当“leader”的服务器，和零个或多个充当“follower”的服务器。 leader处理对分区的所有读写请求，而follower则被动地复制领导者。 如果领导者失败，则跟随者之一将自动成为新领导者。 每个服务器充当其某些分区的领导者，而充当其他分区的跟随者，因此群集中的负载得到了很好的平衡。

### 3 生产者

生产者将数据发布到他们选择的topic。 生产者负责选择将哪个记录分配给主题中的哪个partition。 可以以循环方式完成此操作，仅是为了平衡负载，也可以根据某些语义分区功能（例如基于记录中的某些键）进行此操作。 一秒钟就可以了解更多有关分区的信息！

### 4 消费者

消费者使用consumer group name作为唯一标识，并且发布到主题的每条记录都会传递到每个订阅消费者组中的一个消费者实例。 消费者实例可以在单独的进程中或在单独的机器上。

如果所有消费者实例都具有相同的消费者组，那么将在这些消费者实例上有效地平衡记录。

如果所有消费者实例具有不同的消费者组，则每条记录将广播到所有消费者进程。

![img](http://kafka.apache.org/23/images/consumer-groups.png)

一个由两台服务器组成的Kafka集群，其中包含四个带有两个消费者组的partition（P0-P3）。消费者组A有两个消费者实例，组B有四个。

我们发现topic共有两个消费者组A、B，每个消费者组都是一个“逻辑订阅者”。**每个组均由许多消费者实例组成，以实现可伸缩性和容错能力**。这无非就是发布-订阅语义，其中订阅者是消费者的集群而不是单个进程。

在Kafka中实现消费的方式是，通过在消费者实例上划分分区，以便每个实例在任何时间点都是分区“公平份额”的排他消费者。 Kafka协议动态处理了维护组成员身份的过程。如果新实例加入该组，它们将接管该组其他成员的某些分区；如果实例死亡，则其分区将分配给其余实例。

Kafka仅提供分区中记录的总顺序，而不提供主题中不同分区之间的记录。对于大多数应用程序，按分区排序以及按key对数据进行分区的能力就足够了。但是，如果您需要记录的总订单量，则可以通过只有一个分区的topic来实现，尽管这将意味着每个消费者组只有一个使用者进程。

个人理解：对于一个消费者组来说，每个partition只能供一个消费者实例来消费，不能多个消费者实例同时消费一个partition。

### 5 保证

在较高级别上，Kafka提供以下保证：

**生产者在分区级别的有序性**：生产者发送到特定主题分区的消息将按其发送顺序追加。 也就是说，如果记录M1是由与记录M2相同的生产者发送的，并且首先发送M1，则M1的偏移量将小于M2，并在日志中更早地出现。

**消费者在分区级别的有序性**：消费者实例按记录在日志中的存储顺序查看记录。

**容错性**：对于replicationFactor（复制因子）为N的topic，我们最多可以容忍N-1个服务器故障，而不会丢失提交给日志的任何记录。（replicationFactor参数的意思是，保留几份follower副本。这里不包括leader数量）

### 6 用于消息系统

Kafka的流概念与传统的企业消息传递系统相比如何？

消息传递传统上有两种模式：**队列**、**发布-订阅**。在队列中，一组消费者可以从服务器读取数据，并且每条记录都进入其中一个；在发布-订阅记录中广播给所有消费者。这两个模型中的每一个都有优点和缺点。队列的优势在于，它允许您将数据处理划分到多个使用者实例上，从而扩展处理量。不幸的是，队列不是多用户的——一旦数据被一个进程读取，就会丢失。发布－订阅允许您将数据广播到多个进程，但是由于每条消息都传递给每个订阅者，因此无法扩展处理。

Kafka的消费者组概念概括了这两个概念。与队列一样，消费者组允许您将数据处理划分给一组进程（消费者组的成员）。与发布订阅一样，Kafka允许您将消息广播到多个消费者组。

Kafka模型的优势在于，每个主题都具有这些属性-可以扩展处理范围，并且是多订阅者-无需选择其中一个。

与传统的消息传递系统相比，Kafka还具有更强的订阅保证。

传统队列将记录按顺序保留在服务器上，如果多个消费者从队列中消费，则服务器将按记录的存储顺序分发记录。但是，尽管服务器按顺序分发记录，但是这些记录是异步传递给使用者的，因此它们可能会在不同的使用者上无序到达。这实际上意味着在并行使用的情况下会丢失记录的顺序。消息传递系统通常通过具有“专用使用者”的概念来解决此问题，该概念仅允许一个进程从队列中使用，但是，这当然意味着在处理中没有并行性。

Kafka做得更好。通过在topic内具有并行性（即分区）的概念，Kafka能够在用户进程池中提供**排序保证**和**负载均衡**。这是通过将topic中的分区分配给消费者组中的消费者来实现的，以便**每个分区都由组中的一个消费者完全消费**。通过这样做，我们确保消费者是该分区的唯一读取器，并按顺序使用数据。由于存在许多分区，因此仍然可以平衡许多消费者实例上的负载。但是请注意，消费者组中的消费者实例不能超过分区数。

### 7 用于存储系统

任何允许发布与使用无关的数据的消息队列，都有效地充当了运行中消息的存储系统。 Kafka的不同之处在于它是一个非常好的存储系统。

写入Kafka的数据将写入磁盘并进行复制以实现容错功能。 Kafka允许生产者等待确认，以便直到完全复制并确保即使写入失败的服务器也可以保留写入，写入才被认为是完整的。

Kafka的磁盘结构可以很好地扩展使用——无论服务器上有50 KB还是50 TB的持久数据，Kafka的性能都一样。

认真对待存储并允许客户端控制其读取位置的结果是，您可以将Kafka视为一种专用于高性能，低延迟提交日志存储，复制和传播的专用分布式文件系统。

有关Kafka的提交日志存储和复制设计的详细信息，请阅读此页面。

### 8 用于流处理

仅读取，写入和存储数据流是不够的，目的是实现对流的实时处理。

在Kafka中，流处理器会从输入topic中获取连续数据流，对该输入进行一些处理并生成连续数据流以输出topic。例如，零售应用程序可以接受销售和发货的输入流，并输出根据此数据计算出的重新订购和价格调整流。

可以直接使用生产者和消费者API进行简单处理。但是，对于更复杂的转换，Kafka提供了完全集成的Streams API。这允许构建执行庞大的流处理的应用程序，这些应用程序计算流的聚合或将流连接在一起。该功能有助于解决此类应用程序所面临的难题：处理无序数据，在代码更改时重新处理输入，执行状态计算等。

流API建立在Kafka提供的核心原语之上：它使用生产者和消费者API作为输入，使用Kafka进行状态存储，并使用相同的组机制来实现流处理器实例之间的容错。

### 9 总结

消息传递，存储和流处理的这种组合看似不寻常，但这对于Kafka作为流平台的角色而言至关重要。

像HDFS这样的分布式文件系统允许存储静态文件以进行批处理。实际上，像这样的系统可以存储和处理过去的历史数据。

传统的企业消息传递系统允许处理将来的消息，这些消息将在您订阅后到达。以这种方式构建的应用程序会在将来的数据到达时对其进行处理。

Kafka结合了这两项功能，对于将Kafka用作流应用程序平台和流数据管道平台而言，这种结合至关重要。

通过结合存储和低延迟订阅，流应用程序可以以相同的方式处理过去和将来的数据。那是一个单一的应用程序可以处理历史记录中存储的数据，而不是在到达最后一条记录时结束，而是可以在将来的数据到达时继续进行处理。这是流处理的通用概念，它包含批处理以及消息驱动的应用程序。

同样，对于流数据管道，对实时事件的订阅组合使得可以将Kafka用于非常低延迟的管道。但是可靠地存储数据的能力使其可以用于必须保证数据传输的关键数据，或与仅定期加载数据或可能停机很长时间进行维护的脱机系统集成。流处理设备使数据到达时可以进行转换。

